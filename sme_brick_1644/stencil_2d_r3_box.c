void stencil_2d_box_BrickBrick_16164_radius3(float *p0, float *p1, int ker_size_x, int ker_size_y, int ker_size_z, int sy, int sz, int dy, int dz, float *coef)
{
	svbool_t mask_x_0,mask_x_1,mask_x_2,mask_y,mask_z,mask_xy,mask_xz,mask_yz,mask_xyz,mask_ext;
	svbool_t p32_all = svdup_b32(true); 

	int brick_index[] = {0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240};
	svint32_t index_vec = svld1(p32_all, brick_index);
	svbool_t prefetch_mask;

	int j_offset[] = {(-1*sy+1*16),(-1*sy+2*16),(-1*sy+3*16),0,(1*16),(2*16),(3*16),(1*sy),(1*sy+1*16),(1*sy+2*16),(1*sy+3*16),(2*sy),(2*sy+1*16),(2*sy+2*16),(2*sy+3*16),(3*sy),(3*sy+1*16),(3*sy+2*16),(3*sy+3*16),(4*sy),(4*sy+1*16),(4*sy+2*16)};
	int k_offset[] = {0,(1*16*4),(2*16*4),(3*16*4)};
	for(int vz = 0; vz < ker_size_z; vz += 4) {
		for(int vy = 0; vy < ker_size_y; vy += 16) {
			float *ptr_src = (p0 + (((vy)/4)*sy + ((vy)%4)*16+((vz)/4)*sz + ((vz)%4)*16*4));
			float *ptr_dst = (p1 + (((vy)/4)*dy + ((vy)%4)*16+((vz)/4)*dz + ((vz)%4)*16*4));
			int vec_size_y = min(ker_size_y - vy, 16), vec_size_z = min(ker_size_z - vz, 4);
			for(int vx = 0; vx < ker_size_x; vx += 16) {
				svzero_mask_za(0x1); svzero_mask_za(0x10); 
				svzero_mask_za(0x2); svzero_mask_za(0x20); 
				svzero_mask_za(0x4); svzero_mask_za(0x40); 
				svzero_mask_za(0x8); svzero_mask_za(0x80); 
				if(vec_size_y == 16 && vec_size_z == 4) {
					
					prefetch_mask = svdup_b32(vx + 16 < ker_size_x);
					svprfb_gather_offset(prefetch_mask, ptr_src + 2*16*4*4 + -1*sy, index_vec, SV_PLDL1KEEP);
					svprfb_gather_offset(prefetch_mask, ptr_src + 2*16*4*4 + 0*sy, index_vec, SV_PLDL1KEEP);
					svprfb_gather_offset(prefetch_mask, ptr_src + 2*16*4*4 + 1*sy, index_vec, SV_PLDL1KEEP);
					svprfb_gather_offset(prefetch_mask, ptr_src + 2*16*4*4 + 2*sy, index_vec, SV_PLDL1KEEP);
					svprfb_gather_offset(prefetch_mask, ptr_src + 2*16*4*4 + 3*sy, index_vec, SV_PLDL1KEEP);
					svprfb_gather_offset(prefetch_mask, ptr_src + 2*16*4*4 + 4*sy, index_vec, SV_PLDL1KEEP);

					// declare input vector registers
					svfloat32_t iv0_000,iv0_001,iv0_002; 
					svfloat32_t iv1_000,iv1_001,iv1_002; 
					svfloat32_t iv2_000,iv2_001,iv2_002; 
					svfloat32_t iv3_000,iv3_001,iv3_002; 
					svfloat32_t spv000,spv100,spv200,spv300; 
					// declare input coefficients
					svfloat32_t alpha_vec_0 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_1 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_2 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_3 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_4 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_5 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_6 = svdup_f32_x(p32_all, 0); 
					mask_x_0 = svwhilelt_b32(0, ker_size_x - vx + 3 + 16); 
					mask_x_1 = svwhilelt_b32(16, ker_size_x - vx + 3 + 16); 
					mask_x_2 = svwhilelt_b32(32, ker_size_x - vx + 3 + 16); 
					mask_ext = svwhilelt_b32(0, 13); mask_ext = sveor_z(p32_all, mask_ext, p32_all); 
					mask_x_0 = svand_z(p32_all, mask_x_0, mask_ext); 
					for(int ry = 0; ry < 7; ry += 1) {
						float* alpha_loc = coef + ry*(2*3 + 1);
						alpha_vec_0 = svinsr(alpha_vec_0, alpha_loc[0]); 
						iv0_000 = svld1(mask_x_0, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + 0]); 
						iv0_001 = svld1(mask_x_1, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); 
						iv0_002 = svld1(mask_x_2, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv000 = svext(iv0_000, iv0_001, 13); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_0, spv000); 
						iv1_000 = svld1(mask_x_0, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + 0]); 
						iv1_001 = svld1(mask_x_1, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); 
						iv1_002 = svld1(mask_x_2, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv100 = svext(iv1_000, iv1_001, 13); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_0, spv100); 
						iv2_000 = svld1(mask_x_0, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + 0]); 
						iv2_001 = svld1(mask_x_1, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); 
						iv2_002 = svld1(mask_x_2, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv200 = svext(iv2_000, iv2_001, 13); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_0, spv200); 
						iv3_000 = svld1(mask_x_0, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + 0]); 
						iv3_001 = svld1(mask_x_1, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); 
						iv3_002 = svld1(mask_x_2, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv300 = svext(iv3_000, iv3_001, 13); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_0, spv300); 
						alpha_vec_1 = svinsr(alpha_vec_1, alpha_loc[1]); 
						spv000 = svext(iv0_000, iv0_001, 14); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_1, spv000); 
						spv100 = svext(iv1_000, iv1_001, 14); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_1, spv100); 
						spv200 = svext(iv2_000, iv2_001, 14); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_1, spv200); 
						spv300 = svext(iv3_000, iv3_001, 14); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_1, spv300); 
						alpha_vec_2 = svinsr(alpha_vec_2, alpha_loc[2]); 
						spv000 = svext(iv0_000, iv0_001, 15); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_2, spv000); 
						spv100 = svext(iv1_000, iv1_001, 15); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_2, spv100); 
						spv200 = svext(iv2_000, iv2_001, 15); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_2, spv200); 
						spv300 = svext(iv3_000, iv3_001, 15); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_2, spv300); 
						alpha_vec_3 = svinsr(alpha_vec_3, alpha_loc[3]); 
						spv000 = svext(iv0_001, iv0_002, 0); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_3, spv000); 
						spv100 = svext(iv1_001, iv1_002, 0); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_3, spv100); 
						spv200 = svext(iv2_001, iv2_002, 0); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_3, spv200); 
						spv300 = svext(iv3_001, iv3_002, 0); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_3, spv300); 
						alpha_vec_4 = svinsr(alpha_vec_4, alpha_loc[4]); 
						spv000 = svext(iv0_001, iv0_002, 1); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_4, spv000); 
						spv100 = svext(iv1_001, iv1_002, 1); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_4, spv100); 
						spv200 = svext(iv2_001, iv2_002, 1); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_4, spv200); 
						spv300 = svext(iv3_001, iv3_002, 1); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_4, spv300); 
						alpha_vec_5 = svinsr(alpha_vec_5, alpha_loc[5]); 
						spv000 = svext(iv0_001, iv0_002, 2); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_5, spv000); 
						spv100 = svext(iv1_001, iv1_002, 2); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_5, spv100); 
						spv200 = svext(iv2_001, iv2_002, 2); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_5, spv200); 
						spv300 = svext(iv3_001, iv3_002, 2); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_5, spv300); 
						alpha_vec_6 = svinsr(alpha_vec_6, alpha_loc[6]); 
						spv000 = svext(iv0_001, iv0_002, 3); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_6, spv000); 
						spv100 = svext(iv1_001, iv1_002, 3); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_6, spv100); 
						spv200 = svext(iv2_001, iv2_002, 3); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_6, spv200); 
						spv300 = svext(iv3_001, iv3_002, 3); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_6, spv300); 
					}
					for(int ry = 7; ry < 22; ry += 1) {
						alpha_vec_0 = svinsr(alpha_vec_0, 0); 
						iv0_000 = svld1(mask_x_0, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + 0]); 
						iv0_001 = svld1(mask_x_1, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); 
						iv0_002 = svld1(mask_x_2, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv000 = svext(iv0_000, iv0_001, 13); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_0, spv000); 
						iv1_000 = svld1(mask_x_0, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + 0]); 
						iv1_001 = svld1(mask_x_1, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); 
						iv1_002 = svld1(mask_x_2, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv100 = svext(iv1_000, iv1_001, 13); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_0, spv100); 
						iv2_000 = svld1(mask_x_0, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + 0]); 
						iv2_001 = svld1(mask_x_1, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); 
						iv2_002 = svld1(mask_x_2, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv200 = svext(iv2_000, iv2_001, 13); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_0, spv200); 
						iv3_000 = svld1(mask_x_0, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + 0]); 
						iv3_001 = svld1(mask_x_1, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); 
						iv3_002 = svld1(mask_x_2, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv300 = svext(iv3_000, iv3_001, 13); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_0, spv300); 
						alpha_vec_1 = svinsr(alpha_vec_1, 0); 
						spv000 = svext(iv0_000, iv0_001, 14); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_1, spv000); 
						spv100 = svext(iv1_000, iv1_001, 14); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_1, spv100); 
						spv200 = svext(iv2_000, iv2_001, 14); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_1, spv200); 
						spv300 = svext(iv3_000, iv3_001, 14); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_1, spv300); 
						alpha_vec_2 = svinsr(alpha_vec_2, 0); 
						spv000 = svext(iv0_000, iv0_001, 15); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_2, spv000); 
						spv100 = svext(iv1_000, iv1_001, 15); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_2, spv100); 
						spv200 = svext(iv2_000, iv2_001, 15); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_2, spv200); 
						spv300 = svext(iv3_000, iv3_001, 15); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_2, spv300); 
						alpha_vec_3 = svinsr(alpha_vec_3, 0); 
						spv000 = svext(iv0_001, iv0_002, 0); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_3, spv000); 
						spv100 = svext(iv1_001, iv1_002, 0); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_3, spv100); 
						spv200 = svext(iv2_001, iv2_002, 0); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_3, spv200); 
						spv300 = svext(iv3_001, iv3_002, 0); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_3, spv300); 
						alpha_vec_4 = svinsr(alpha_vec_4, 0); 
						spv000 = svext(iv0_001, iv0_002, 1); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_4, spv000); 
						spv100 = svext(iv1_001, iv1_002, 1); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_4, spv100); 
						spv200 = svext(iv2_001, iv2_002, 1); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_4, spv200); 
						spv300 = svext(iv3_001, iv3_002, 1); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_4, spv300); 
						alpha_vec_5 = svinsr(alpha_vec_5, 0); 
						spv000 = svext(iv0_001, iv0_002, 2); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_5, spv000); 
						spv100 = svext(iv1_001, iv1_002, 2); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_5, spv100); 
						spv200 = svext(iv2_001, iv2_002, 2); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_5, spv200); 
						spv300 = svext(iv3_001, iv3_002, 2); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_5, spv300); 
						alpha_vec_6 = svinsr(alpha_vec_6, 0); 
						spv000 = svext(iv0_001, iv0_002, 3); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_6, spv000); 
						spv100 = svext(iv1_001, iv1_002, 3); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_6, spv100); 
						spv200 = svext(iv2_001, iv2_002, 3); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_6, spv200); 
						spv300 = svext(iv3_001, iv3_002, 3); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_6, spv300); 
					}
					mask_x_0 = svwhilelt_b32(0, ker_size_x - vx); 
					svst1_hor_za32(0, 0, mask_x_0, &ptr_dst[0 + 0]); 
					svst1_hor_za32(0, 1, mask_x_0, &ptr_dst[0 + (1*16)]); 
					svst1_hor_za32(0, 2, mask_x_0, &ptr_dst[0 + (2*16)]); 
					svst1_hor_za32(0, 3, mask_x_0, &ptr_dst[0 + (3*16)]); 
					svst1_hor_za32(0, 4, mask_x_0, &ptr_dst[0 + (1*dy)]); 
					svst1_hor_za32(0, 5, mask_x_0, &ptr_dst[0 + (1*dy+1*16)]); 
					svst1_hor_za32(0, 6, mask_x_0, &ptr_dst[0 + (1*dy+2*16)]); 
					svst1_hor_za32(0, 7, mask_x_0, &ptr_dst[0 + (1*dy+3*16)]); 
					svst1_hor_za32(0, 8, mask_x_0, &ptr_dst[0 + (2*dy)]); 
					svst1_hor_za32(0, 9, mask_x_0, &ptr_dst[0 + (2*dy+1*16)]); 
					svst1_hor_za32(0, 10, mask_x_0, &ptr_dst[0 + (2*dy+2*16)]); 
					svst1_hor_za32(0, 11, mask_x_0, &ptr_dst[0 + (2*dy+3*16)]); 
					svst1_hor_za32(0, 12, mask_x_0, &ptr_dst[0 + (3*dy)]); 
					svst1_hor_za32(0, 13, mask_x_0, &ptr_dst[0 + (3*dy+1*16)]); 
					svst1_hor_za32(0, 14, mask_x_0, &ptr_dst[0 + (3*dy+2*16)]); 
					svst1_hor_za32(0, 15, mask_x_0, &ptr_dst[0 + (3*dy+3*16)]); 
					svst1_hor_za32(1, 0, mask_x_0, &ptr_dst[0 + (1*16*4)]); 
					svst1_hor_za32(1, 1, mask_x_0, &ptr_dst[0 + (1*16+1*16*4)]); 
					svst1_hor_za32(1, 2, mask_x_0, &ptr_dst[0 + (2*16+1*16*4)]); 
					svst1_hor_za32(1, 3, mask_x_0, &ptr_dst[0 + (3*16+1*16*4)]); 
					svst1_hor_za32(1, 4, mask_x_0, &ptr_dst[0 + (1*dy+1*16*4)]); 
					svst1_hor_za32(1, 5, mask_x_0, &ptr_dst[0 + (1*dy+1*16+1*16*4)]); 
					svst1_hor_za32(1, 6, mask_x_0, &ptr_dst[0 + (1*dy+2*16+1*16*4)]); 
					svst1_hor_za32(1, 7, mask_x_0, &ptr_dst[0 + (1*dy+3*16+1*16*4)]); 
					svst1_hor_za32(1, 8, mask_x_0, &ptr_dst[0 + (2*dy+1*16*4)]); 
					svst1_hor_za32(1, 9, mask_x_0, &ptr_dst[0 + (2*dy+1*16+1*16*4)]); 
					svst1_hor_za32(1, 10, mask_x_0, &ptr_dst[0 + (2*dy+2*16+1*16*4)]); 
					svst1_hor_za32(1, 11, mask_x_0, &ptr_dst[0 + (2*dy+3*16+1*16*4)]); 
					svst1_hor_za32(1, 12, mask_x_0, &ptr_dst[0 + (3*dy+1*16*4)]); 
					svst1_hor_za32(1, 13, mask_x_0, &ptr_dst[0 + (3*dy+1*16+1*16*4)]); 
					svst1_hor_za32(1, 14, mask_x_0, &ptr_dst[0 + (3*dy+2*16+1*16*4)]); 
					svst1_hor_za32(1, 15, mask_x_0, &ptr_dst[0 + (3*dy+3*16+1*16*4)]); 
					svst1_hor_za32(2, 0, mask_x_0, &ptr_dst[0 + (2*16*4)]); 
					svst1_hor_za32(2, 1, mask_x_0, &ptr_dst[0 + (1*16+2*16*4)]); 
					svst1_hor_za32(2, 2, mask_x_0, &ptr_dst[0 + (2*16+2*16*4)]); 
					svst1_hor_za32(2, 3, mask_x_0, &ptr_dst[0 + (3*16+2*16*4)]); 
					svst1_hor_za32(2, 4, mask_x_0, &ptr_dst[0 + (1*dy+2*16*4)]); 
					svst1_hor_za32(2, 5, mask_x_0, &ptr_dst[0 + (1*dy+1*16+2*16*4)]); 
					svst1_hor_za32(2, 6, mask_x_0, &ptr_dst[0 + (1*dy+2*16+2*16*4)]); 
					svst1_hor_za32(2, 7, mask_x_0, &ptr_dst[0 + (1*dy+3*16+2*16*4)]); 
					svst1_hor_za32(2, 8, mask_x_0, &ptr_dst[0 + (2*dy+2*16*4)]); 
					svst1_hor_za32(2, 9, mask_x_0, &ptr_dst[0 + (2*dy+1*16+2*16*4)]); 
					svst1_hor_za32(2, 10, mask_x_0, &ptr_dst[0 + (2*dy+2*16+2*16*4)]); 
					svst1_hor_za32(2, 11, mask_x_0, &ptr_dst[0 + (2*dy+3*16+2*16*4)]); 
					svst1_hor_za32(2, 12, mask_x_0, &ptr_dst[0 + (3*dy+2*16*4)]); 
					svst1_hor_za32(2, 13, mask_x_0, &ptr_dst[0 + (3*dy+1*16+2*16*4)]); 
					svst1_hor_za32(2, 14, mask_x_0, &ptr_dst[0 + (3*dy+2*16+2*16*4)]); 
					svst1_hor_za32(2, 15, mask_x_0, &ptr_dst[0 + (3*dy+3*16+2*16*4)]); 
					svst1_hor_za32(3, 0, mask_x_0, &ptr_dst[0 + (3*16*4)]); 
					svst1_hor_za32(3, 1, mask_x_0, &ptr_dst[0 + (1*16+3*16*4)]); 
					svst1_hor_za32(3, 2, mask_x_0, &ptr_dst[0 + (2*16+3*16*4)]); 
					svst1_hor_za32(3, 3, mask_x_0, &ptr_dst[0 + (3*16+3*16*4)]); 
					svst1_hor_za32(3, 4, mask_x_0, &ptr_dst[0 + (1*dy+3*16*4)]); 
					svst1_hor_za32(3, 5, mask_x_0, &ptr_dst[0 + (1*dy+1*16+3*16*4)]); 
					svst1_hor_za32(3, 6, mask_x_0, &ptr_dst[0 + (1*dy+2*16+3*16*4)]); 
					svst1_hor_za32(3, 7, mask_x_0, &ptr_dst[0 + (1*dy+3*16+3*16*4)]); 
					svst1_hor_za32(3, 8, mask_x_0, &ptr_dst[0 + (2*dy+3*16*4)]); 
					svst1_hor_za32(3, 9, mask_x_0, &ptr_dst[0 + (2*dy+1*16+3*16*4)]); 
					svst1_hor_za32(3, 10, mask_x_0, &ptr_dst[0 + (2*dy+2*16+3*16*4)]); 
					svst1_hor_za32(3, 11, mask_x_0, &ptr_dst[0 + (2*dy+3*16+3*16*4)]); 
					svst1_hor_za32(3, 12, mask_x_0, &ptr_dst[0 + (3*dy+3*16*4)]); 
					svst1_hor_za32(3, 13, mask_x_0, &ptr_dst[0 + (3*dy+1*16+3*16*4)]); 
					svst1_hor_za32(3, 14, mask_x_0, &ptr_dst[0 + (3*dy+2*16+3*16*4)]); 
					svst1_hor_za32(3, 15, mask_x_0, &ptr_dst[0 + (3*dy+3*16+3*16*4)]); 
				} else {
					// declare input vector registers
					svfloat32_t iv0_000,iv0_001,iv0_002; 
					svfloat32_t iv1_000,iv1_001,iv1_002; 
					svfloat32_t iv2_000,iv2_001,iv2_002; 
					svfloat32_t iv3_000,iv3_001,iv3_002; 
					svfloat32_t spv000,spv100,spv200,spv300; 
					// declare input coefficients
					svfloat32_t alpha_vec_0 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_1 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_2 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_3 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_4 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_5 = svdup_f32_x(p32_all, 0); 
					svfloat32_t alpha_vec_6 = svdup_f32_x(p32_all, 0); 
					mask_x_0 = svwhilelt_b32(0, ker_size_x - vx + 3 + 16); 
					mask_x_1 = svwhilelt_b32(16, ker_size_x - vx + 3 + 16); 
					mask_x_2 = svwhilelt_b32(32, ker_size_x - vx + 3 + 16); 
					mask_ext = svwhilelt_b32(0, 13); mask_ext = sveor_z(p32_all, mask_ext, p32_all); 
					mask_x_0 = svand_z(p32_all, mask_x_0, mask_ext); 
					for(int ry = 0; ry < 7; ry += 1) {
						float* alpha_loc = coef + ry*(2*3 + 1);
						alpha_vec_0 = svinsr(alpha_vec_0, alpha_loc[0]); 
						mask_z = svdup_b32(0 < ker_size_z - vz + 3 - 0); 
						mask_y = svdup_b32(0 < ker_size_y - vy + 3 - (ry - 3)); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_yz, mask_x_0); iv0_000 = svld1(mask_xyz, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + 0]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_1); iv0_001 = svld1(mask_xyz, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_2); iv0_002 = svld1(mask_xyz, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv000 = svext(iv0_000, iv0_001, 13); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_0, spv000); 
						mask_z = svdup_b32(0 < ker_size_z - vz + 3 - 1); 
						mask_y = svdup_b32(0 < ker_size_y - vy + 3 - (ry - 3)); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_yz, mask_x_0); iv1_000 = svld1(mask_xyz, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + 0]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_1); iv1_001 = svld1(mask_xyz, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_2); iv1_002 = svld1(mask_xyz, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv100 = svext(iv1_000, iv1_001, 13); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_0, spv100); 
						mask_z = svdup_b32(0 < ker_size_z - vz + 3 - 2); 
						mask_y = svdup_b32(0 < ker_size_y - vy + 3 - (ry - 3)); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_yz, mask_x_0); iv2_000 = svld1(mask_xyz, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + 0]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_1); iv2_001 = svld1(mask_xyz, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_2); iv2_002 = svld1(mask_xyz, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv200 = svext(iv2_000, iv2_001, 13); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_0, spv200); 
						mask_z = svdup_b32(0 < ker_size_z - vz + 3 - 3); 
						mask_y = svdup_b32(0 < ker_size_y - vy + 3 - (ry - 3)); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_yz, mask_x_0); iv3_000 = svld1(mask_xyz, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + 0]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_1); iv3_001 = svld1(mask_xyz, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_2); iv3_002 = svld1(mask_xyz, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv300 = svext(iv3_000, iv3_001, 13); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_0, spv300); 
						alpha_vec_1 = svinsr(alpha_vec_1, alpha_loc[1]); 
						spv000 = svext(iv0_000, iv0_001, 14); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_1, spv000); 
						spv100 = svext(iv1_000, iv1_001, 14); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_1, spv100); 
						spv200 = svext(iv2_000, iv2_001, 14); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_1, spv200); 
						spv300 = svext(iv3_000, iv3_001, 14); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_1, spv300); 
						alpha_vec_2 = svinsr(alpha_vec_2, alpha_loc[2]); 
						spv000 = svext(iv0_000, iv0_001, 15); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_2, spv000); 
						spv100 = svext(iv1_000, iv1_001, 15); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_2, spv100); 
						spv200 = svext(iv2_000, iv2_001, 15); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_2, spv200); 
						spv300 = svext(iv3_000, iv3_001, 15); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_2, spv300); 
						alpha_vec_3 = svinsr(alpha_vec_3, alpha_loc[3]); 
						spv000 = svext(iv0_001, iv0_002, 0); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_3, spv000); 
						spv100 = svext(iv1_001, iv1_002, 0); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_3, spv100); 
						spv200 = svext(iv2_001, iv2_002, 0); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_3, spv200); 
						spv300 = svext(iv3_001, iv3_002, 0); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_3, spv300); 
						alpha_vec_4 = svinsr(alpha_vec_4, alpha_loc[4]); 
						spv000 = svext(iv0_001, iv0_002, 1); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_4, spv000); 
						spv100 = svext(iv1_001, iv1_002, 1); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_4, spv100); 
						spv200 = svext(iv2_001, iv2_002, 1); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_4, spv200); 
						spv300 = svext(iv3_001, iv3_002, 1); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_4, spv300); 
						alpha_vec_5 = svinsr(alpha_vec_5, alpha_loc[5]); 
						spv000 = svext(iv0_001, iv0_002, 2); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_5, spv000); 
						spv100 = svext(iv1_001, iv1_002, 2); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_5, spv100); 
						spv200 = svext(iv2_001, iv2_002, 2); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_5, spv200); 
						spv300 = svext(iv3_001, iv3_002, 2); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_5, spv300); 
						alpha_vec_6 = svinsr(alpha_vec_6, alpha_loc[6]); 
						spv000 = svext(iv0_001, iv0_002, 3); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_6, spv000); 
						spv100 = svext(iv1_001, iv1_002, 3); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_6, spv100); 
						spv200 = svext(iv2_001, iv2_002, 3); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_6, spv200); 
						spv300 = svext(iv3_001, iv3_002, 3); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_6, spv300); 
					}
					for(int ry = 7; ry < 22; ry += 1) {
						alpha_vec_0 = svinsr(alpha_vec_0, 0); 
						mask_z = svdup_b32(0 < ker_size_z - vz + 3 - 0); 
						mask_y = svdup_b32(0 < ker_size_y - vy + 3 - (ry - 3)); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_yz, mask_x_0); iv0_000 = svld1(mask_xyz, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + 0]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_1); iv0_001 = svld1(mask_xyz, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_2); iv0_002 = svld1(mask_xyz, &ptr_src[k_offset[0] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv000 = svext(iv0_000, iv0_001, 13); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_0, spv000); 
						mask_z = svdup_b32(0 < ker_size_z - vz + 3 - 1); 
						mask_y = svdup_b32(0 < ker_size_y - vy + 3 - (ry - 3)); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_yz, mask_x_0); iv1_000 = svld1(mask_xyz, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + 0]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_1); iv1_001 = svld1(mask_xyz, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_2); iv1_002 = svld1(mask_xyz, &ptr_src[k_offset[1] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv100 = svext(iv1_000, iv1_001, 13); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_0, spv100); 
						mask_z = svdup_b32(0 < ker_size_z - vz + 3 - 2); 
						mask_y = svdup_b32(0 < ker_size_y - vy + 3 - (ry - 3)); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_yz, mask_x_0); iv2_000 = svld1(mask_xyz, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + 0]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_1); iv2_001 = svld1(mask_xyz, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_2); iv2_002 = svld1(mask_xyz, &ptr_src[k_offset[2] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv200 = svext(iv2_000, iv2_001, 13); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_0, spv200); 
						mask_z = svdup_b32(0 < ker_size_z - vz + 3 - 3); 
						mask_y = svdup_b32(0 < ker_size_y - vy + 3 - (ry - 3)); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_yz, mask_x_0); iv3_000 = svld1(mask_xyz, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + 0]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_1); iv3_001 = svld1(mask_xyz, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + (1*16*4*4)]); mask_xyz = svand_z(p32_all, mask_yz, mask_x_2); iv3_002 = svld1(mask_xyz, &ptr_src[k_offset[3] + j_offset[ry] + (-1*16*4*4) + (2*16*4*4)]); 
						spv300 = svext(iv3_000, iv3_001, 13); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_0, spv300); 
						alpha_vec_1 = svinsr(alpha_vec_1, 0); 
						spv000 = svext(iv0_000, iv0_001, 14); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_1, spv000); 
						spv100 = svext(iv1_000, iv1_001, 14); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_1, spv100); 
						spv200 = svext(iv2_000, iv2_001, 14); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_1, spv200); 
						spv300 = svext(iv3_000, iv3_001, 14); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_1, spv300); 
						alpha_vec_2 = svinsr(alpha_vec_2, 0); 
						spv000 = svext(iv0_000, iv0_001, 15); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_2, spv000); 
						spv100 = svext(iv1_000, iv1_001, 15); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_2, spv100); 
						spv200 = svext(iv2_000, iv2_001, 15); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_2, spv200); 
						spv300 = svext(iv3_000, iv3_001, 15); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_2, spv300); 
						alpha_vec_3 = svinsr(alpha_vec_3, 0); 
						spv000 = svext(iv0_001, iv0_002, 0); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_3, spv000); 
						spv100 = svext(iv1_001, iv1_002, 0); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_3, spv100); 
						spv200 = svext(iv2_001, iv2_002, 0); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_3, spv200); 
						spv300 = svext(iv3_001, iv3_002, 0); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_3, spv300); 
						alpha_vec_4 = svinsr(alpha_vec_4, 0); 
						spv000 = svext(iv0_001, iv0_002, 1); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_4, spv000); 
						spv100 = svext(iv1_001, iv1_002, 1); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_4, spv100); 
						spv200 = svext(iv2_001, iv2_002, 1); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_4, spv200); 
						spv300 = svext(iv3_001, iv3_002, 1); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_4, spv300); 
						alpha_vec_5 = svinsr(alpha_vec_5, 0); 
						spv000 = svext(iv0_001, iv0_002, 2); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_5, spv000); 
						spv100 = svext(iv1_001, iv1_002, 2); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_5, spv100); 
						spv200 = svext(iv2_001, iv2_002, 2); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_5, spv200); 
						spv300 = svext(iv3_001, iv3_002, 2); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_5, spv300); 
						alpha_vec_6 = svinsr(alpha_vec_6, 0); 
						spv000 = svext(iv0_001, iv0_002, 3); svmopa_za32_m(0, p32_all, p32_all, alpha_vec_6, spv000); 
						spv100 = svext(iv1_001, iv1_002, 3); svmopa_za32_m(1, p32_all, p32_all, alpha_vec_6, spv100); 
						spv200 = svext(iv2_001, iv2_002, 3); svmopa_za32_m(2, p32_all, p32_all, alpha_vec_6, spv200); 
						spv300 = svext(iv3_001, iv3_002, 3); svmopa_za32_m(3, p32_all, p32_all, alpha_vec_6, spv300); 
					}
					mask_x_0 = svwhilelt_b32(0, ker_size_x - vx); 
					mask_z = svdup_b32(0 < ker_size_z - vz); 
					mask_y = svdup_b32(0 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 0, mask_xyz, &ptr_dst[0 + 0]); 
					mask_y = svdup_b32(1 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 1, mask_xyz, &ptr_dst[0 + (1*16)]); 
					mask_y = svdup_b32(2 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 2, mask_xyz, &ptr_dst[0 + (2*16)]); 
					mask_y = svdup_b32(3 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 3, mask_xyz, &ptr_dst[0 + (3*16)]); 
					mask_y = svdup_b32(4 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 4, mask_xyz, &ptr_dst[0 + (1*dy)]); 
					mask_y = svdup_b32(5 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 5, mask_xyz, &ptr_dst[0 + (1*dy+1*16)]); 
					mask_y = svdup_b32(6 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 6, mask_xyz, &ptr_dst[0 + (1*dy+2*16)]); 
					mask_y = svdup_b32(7 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 7, mask_xyz, &ptr_dst[0 + (1*dy+3*16)]); 
					mask_y = svdup_b32(8 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 8, mask_xyz, &ptr_dst[0 + (2*dy)]); 
					mask_y = svdup_b32(9 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 9, mask_xyz, &ptr_dst[0 + (2*dy+1*16)]); 
					mask_y = svdup_b32(10 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 10, mask_xyz, &ptr_dst[0 + (2*dy+2*16)]); 
					mask_y = svdup_b32(11 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 11, mask_xyz, &ptr_dst[0 + (2*dy+3*16)]); 
					mask_y = svdup_b32(12 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 12, mask_xyz, &ptr_dst[0 + (3*dy)]); 
					mask_y = svdup_b32(13 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 13, mask_xyz, &ptr_dst[0 + (3*dy+1*16)]); 
					mask_y = svdup_b32(14 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 14, mask_xyz, &ptr_dst[0 + (3*dy+2*16)]); 
					mask_y = svdup_b32(15 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(0, 15, mask_xyz, &ptr_dst[0 + (3*dy+3*16)]); 
					mask_z = svdup_b32(1 < ker_size_z - vz); 
					mask_y = svdup_b32(0 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 0, mask_xyz, &ptr_dst[0 + (1*16*4)]); 
					mask_y = svdup_b32(1 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 1, mask_xyz, &ptr_dst[0 + (1*16+1*16*4)]); 
					mask_y = svdup_b32(2 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 2, mask_xyz, &ptr_dst[0 + (2*16+1*16*4)]); 
					mask_y = svdup_b32(3 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 3, mask_xyz, &ptr_dst[0 + (3*16+1*16*4)]); 
					mask_y = svdup_b32(4 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 4, mask_xyz, &ptr_dst[0 + (1*dy+1*16*4)]); 
					mask_y = svdup_b32(5 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 5, mask_xyz, &ptr_dst[0 + (1*dy+1*16+1*16*4)]); 
					mask_y = svdup_b32(6 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 6, mask_xyz, &ptr_dst[0 + (1*dy+2*16+1*16*4)]); 
					mask_y = svdup_b32(7 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 7, mask_xyz, &ptr_dst[0 + (1*dy+3*16+1*16*4)]); 
					mask_y = svdup_b32(8 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 8, mask_xyz, &ptr_dst[0 + (2*dy+1*16*4)]); 
					mask_y = svdup_b32(9 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 9, mask_xyz, &ptr_dst[0 + (2*dy+1*16+1*16*4)]); 
					mask_y = svdup_b32(10 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 10, mask_xyz, &ptr_dst[0 + (2*dy+2*16+1*16*4)]); 
					mask_y = svdup_b32(11 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 11, mask_xyz, &ptr_dst[0 + (2*dy+3*16+1*16*4)]); 
					mask_y = svdup_b32(12 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 12, mask_xyz, &ptr_dst[0 + (3*dy+1*16*4)]); 
					mask_y = svdup_b32(13 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 13, mask_xyz, &ptr_dst[0 + (3*dy+1*16+1*16*4)]); 
					mask_y = svdup_b32(14 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 14, mask_xyz, &ptr_dst[0 + (3*dy+2*16+1*16*4)]); 
					mask_y = svdup_b32(15 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(1, 15, mask_xyz, &ptr_dst[0 + (3*dy+3*16+1*16*4)]); 
					mask_z = svdup_b32(2 < ker_size_z - vz); 
					mask_y = svdup_b32(0 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 0, mask_xyz, &ptr_dst[0 + (2*16*4)]); 
					mask_y = svdup_b32(1 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 1, mask_xyz, &ptr_dst[0 + (1*16+2*16*4)]); 
					mask_y = svdup_b32(2 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 2, mask_xyz, &ptr_dst[0 + (2*16+2*16*4)]); 
					mask_y = svdup_b32(3 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 3, mask_xyz, &ptr_dst[0 + (3*16+2*16*4)]); 
					mask_y = svdup_b32(4 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 4, mask_xyz, &ptr_dst[0 + (1*dy+2*16*4)]); 
					mask_y = svdup_b32(5 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 5, mask_xyz, &ptr_dst[0 + (1*dy+1*16+2*16*4)]); 
					mask_y = svdup_b32(6 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 6, mask_xyz, &ptr_dst[0 + (1*dy+2*16+2*16*4)]); 
					mask_y = svdup_b32(7 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 7, mask_xyz, &ptr_dst[0 + (1*dy+3*16+2*16*4)]); 
					mask_y = svdup_b32(8 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 8, mask_xyz, &ptr_dst[0 + (2*dy+2*16*4)]); 
					mask_y = svdup_b32(9 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 9, mask_xyz, &ptr_dst[0 + (2*dy+1*16+2*16*4)]); 
					mask_y = svdup_b32(10 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 10, mask_xyz, &ptr_dst[0 + (2*dy+2*16+2*16*4)]); 
					mask_y = svdup_b32(11 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 11, mask_xyz, &ptr_dst[0 + (2*dy+3*16+2*16*4)]); 
					mask_y = svdup_b32(12 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 12, mask_xyz, &ptr_dst[0 + (3*dy+2*16*4)]); 
					mask_y = svdup_b32(13 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 13, mask_xyz, &ptr_dst[0 + (3*dy+1*16+2*16*4)]); 
					mask_y = svdup_b32(14 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 14, mask_xyz, &ptr_dst[0 + (3*dy+2*16+2*16*4)]); 
					mask_y = svdup_b32(15 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(2, 15, mask_xyz, &ptr_dst[0 + (3*dy+3*16+2*16*4)]); 
					mask_z = svdup_b32(3 < ker_size_z - vz); 
					mask_y = svdup_b32(0 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 0, mask_xyz, &ptr_dst[0 + (3*16*4)]); 
					mask_y = svdup_b32(1 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 1, mask_xyz, &ptr_dst[0 + (1*16+3*16*4)]); 
					mask_y = svdup_b32(2 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 2, mask_xyz, &ptr_dst[0 + (2*16+3*16*4)]); 
					mask_y = svdup_b32(3 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 3, mask_xyz, &ptr_dst[0 + (3*16+3*16*4)]); 
					mask_y = svdup_b32(4 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 4, mask_xyz, &ptr_dst[0 + (1*dy+3*16*4)]); 
					mask_y = svdup_b32(5 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 5, mask_xyz, &ptr_dst[0 + (1*dy+1*16+3*16*4)]); 
					mask_y = svdup_b32(6 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 6, mask_xyz, &ptr_dst[0 + (1*dy+2*16+3*16*4)]); 
					mask_y = svdup_b32(7 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 7, mask_xyz, &ptr_dst[0 + (1*dy+3*16+3*16*4)]); 
					mask_y = svdup_b32(8 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 8, mask_xyz, &ptr_dst[0 + (2*dy+3*16*4)]); 
					mask_y = svdup_b32(9 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 9, mask_xyz, &ptr_dst[0 + (2*dy+1*16+3*16*4)]); 
					mask_y = svdup_b32(10 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 10, mask_xyz, &ptr_dst[0 + (2*dy+2*16+3*16*4)]); 
					mask_y = svdup_b32(11 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 11, mask_xyz, &ptr_dst[0 + (2*dy+3*16+3*16*4)]); 
					mask_y = svdup_b32(12 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 12, mask_xyz, &ptr_dst[0 + (3*dy+3*16*4)]); 
					mask_y = svdup_b32(13 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 13, mask_xyz, &ptr_dst[0 + (3*dy+1*16+3*16*4)]); 
					mask_y = svdup_b32(14 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 14, mask_xyz, &ptr_dst[0 + (3*dy+2*16+3*16*4)]); 
					mask_y = svdup_b32(15 < ker_size_y - vy); mask_yz = svand_z(p32_all, mask_y, mask_z); mask_xyz = svand_z(p32_all, mask_x_0, mask_yz); svst1_hor_za32(3, 15, mask_xyz, &ptr_dst[0 + (3*dy+3*16+3*16*4)]); 
				}
				ptr_src += (1*16*4*4); ptr_dst += (1*16*4*4);
			}
		}
	}
}
